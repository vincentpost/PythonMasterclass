{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python to fit models to data\n",
    "\n",
    "This notebook describes various methods to fit a function to a set of data points using Python. There are a number of available methods, each with different fitting algoritms and results. The most appropriate method to use depends on the objective of the code. To illustrate the differences it will be shown how the various methods can be applied to fit a straight line to some data points, which are generated in the code cell below. To add noise to the data, the `normal` function from `numpy.random` is used, which takes a keyword argument `scale`, which is the standard deviation of the normal probability distribution. The `size` argument determines the number of randomly-drawn samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 11)\n",
    "intercept = 2.0\n",
    "slope = 1.0\n",
    "y = intercept + slope * x\n",
    "ydata = y + np.random.normal(scale=0.25, size=len(x))\n",
    "\n",
    "# Plot the straight line as well as the data points\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, ydata, 'o');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting the volume - water level relationship for the farm dam water balance study, we used the `polyfit` function. It can be used to fit a straight line as well by specifying the degree of the polynomial as one (`deg=1`). The return value of the function is an array with the coefficients of the polynomial, with the slope being the first element of the array and the intercept the second. Remember that a function can be created using the `poly1d` method, which takes the coefficiens as arguments. The graph below is the same as the previous graph except that it now includes the line (blue dashes) based on the fitted coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoef = np.polyfit(x=x, y=ydata, deg=1)\n",
    "print(pcoef)\n",
    "pfunc = np.poly1d(pcoef)\n",
    "\n",
    "ypoly = pfunc(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, ypoly, 'C0--')\n",
    "plt.plot(x, ydata, 'o');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a function in `scipy.stats` called  `linregress`. This function returns additional information, such as the $r$ value (indicating the goodness of fit) and the standard errors of the fitted slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "res = linregress(x=x, y=ydata)\n",
    "slope = res.slope\n",
    "intercept = res.intercept\n",
    "\n",
    "ylr = intercept + slope * x\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, ylr, 'C0--')\n",
    "plt.plot(x, ydata, 'o')\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For math afficionados, there is also the `lstsq` method in `np.linalg`. The return value of this function is $x$ in \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"screenshot_matrix_equations.png\" alt=\"matrix equations\" height=\"400\">\n",
    "</p>\n",
    "\n",
    "The function returns $x$, the residuals as well as the rank (number of independent columns in $x$) and singular values of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ones((len(x), 2))\n",
    "A[:, 0] = x\n",
    "res = np.linalg.lstsq(A, ydata, rcond=None) # rcond is a parameter related to the calculation of the rank\n",
    "slope, intercept = res[0]\n",
    "\n",
    "ylstsq = intercept + slope * x\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, ylstsq, 'C0--')\n",
    "plt.plot(x, ydata, 'o')\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `minimize` from the `scipy.optimize` library finds the minimum of an objective function, in this case `fdiff`, which returns the sum of squared residuals. The parameters to be optimized are passed as the array `p`. For the `minimize` function, the user must also specify starting guesses of the parameters in `p` using the `x0` keyword argument. Because the function `fdiff` does not only take `p` as an argument, but also `x` and `ydata`, it is necessary to specify this using the `args` keyword argument.\n",
    "\n",
    "The optimzed parameter values are stored in `x` of the return value. The function `minimize` also calculates the Jacobian matrix, which provides information about the parameter sensitivities. See <A href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\">https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html</A> for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def fdiff(p, x, ydata):\n",
    "    intercept = p[0]\n",
    "    slope = p[1]\n",
    "    y = intercept + slope * x\n",
    "    return np.sum((y - ydata)  ** 2)\n",
    "\n",
    "res = minimize(fdiff, x0=[0, 1], args=(x, ydata))\n",
    "\n",
    "intercept = res.x[0]\n",
    "slope = res.x[1]\n",
    "\n",
    "ym = intercept + slope * x\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, ym, 'C0--')\n",
    "plt.plot(x, ydata, 'o')\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `lmfit` package provides a range of non-linear least-squares minimization and curve-fitting functions for Python. It extends the methods of ` scipy.optimize` and provides some of the functionality that PEST also provides. In the code cell below, a similar objective function is provided as the one used before (except that it does not return the sum of squared residuals but simply the residuals). The parameters are stored in an instance of the `Parameters` class and are added using the `add` method. Note that not only the initial guesses are defined using `add` but it is also possible to define minimum and maximum parameter bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "def fdiff(p, x, ydata):\n",
    "    intercept = p[\"intercept\"]\n",
    "    slope = p[\"slope\"]\n",
    "    y = intercept + slope * x\n",
    "    return y - ydata\n",
    "\n",
    "parameters = lmfit.Parameters()\n",
    "parameters.add('intercept', value=0, min=-2.0, max=2.0)\n",
    "parameters.add('slope', value=1.0, min=0.1, max=3.0)\n",
    "mini = lmfit.Minimizer(userfcn=fdiff,\n",
    "                       fcn_args=(x, ydata),\n",
    "                       calc_covar=True,\n",
    "                       params=parameters)\n",
    "res = mini.minimize(method=\"leastsq\")\n",
    "\n",
    "intercept = res.params[\"intercept\"]\n",
    "slope = res.params[\"slope\"]\n",
    "\n",
    "ylmfit = intercept + slope * x\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, ylmfit, 'C0--')\n",
    "plt.plot(x, ydata, 'o')\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how a parameter value can be held constant during the optimization, we rerun the previous example, but now we force the intercept through zero (using `vary=False` for the intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = lmfit.Parameters()\n",
    "parameters.add('intercept', value=0, vary=False)\n",
    "parameters.add('slope', value=1.0, min=0.1, max=3.0)\n",
    "mini = lmfit.Minimizer(userfcn=fdiff,\n",
    "                       fcn_args=(x, ydata),\n",
    "                       calc_covar=True,\n",
    "                       params=parameters)\n",
    "res = mini.minimize(method=\"leastsq\")\n",
    "\n",
    "intercept = res.params[\"intercept\"]\n",
    "slope = res.params[\"slope\"]\n",
    "\n",
    "ylmfit = intercept + slope * x\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, ylmfit, 'C0--')\n",
    "plt.plot(x, ydata, 'o')\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise***: The array `ydata` defines a set of $y$ values of $y = A\\ sin(b x)$ for the $x$ values in `xdata`. Rewrite the function `fdiff` and modify the lmfit function calls to fit find the values of $A$ and $b$ that fit the data points. Be warned that your initial guess has an extreme influence on the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array([0.0, 0.38, 0.76, 1.14, 1.52, 1.9, 2.28, 2.67, 3.05, 3.43, 3.81, 4.19, 4.57, 4.95, 5.33, 5.71, 6.09])\n",
    "ydata = np.array([0.0, 1.38, 2.0, 1.51, 0.19, -1.24, -1.98, -1.63, -0.38, 1.08, 1.94, 1.73, 0.56, -0.92, -1.89, -1.82, -0.74])\n",
    "\n",
    "plt.plot(xdata, ydata, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdiff(p, x, ydata):\n",
    "    # Type your code here\n",
    "    return y - ydata\n",
    "\n",
    "parameters = lmfit.Parameters()\n",
    "# Add your parameter definitions here\n",
    "mini = lmfit.Minimizer(userfcn=fdiff,\n",
    "                       fcn_args=(x, ydata),\n",
    "                       calc_covar=True,\n",
    "                       params=parameters)\n",
    "res = mini.minimize(method=\"leastsq\")\n",
    "\n",
    "# Include code to plot the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on linear regression on Python see <A href=\"https://realpython.com/linear-regression-in-python/\">https://realpython.com/linear-regression-in-python/</A>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
